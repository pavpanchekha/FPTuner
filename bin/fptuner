#!/usr/bin/env python3

import os.path as path
import sys
import time

PYTHON_DIR = path.abspath(path.dirname(__file__))
GIT_DIR = path.split(PYTHON_DIR)[0]
sys.path.append(PYTHON_DIR)
sys.path.append(path.join(GIT_DIR, "src"))
sys.path.append(path.join(GIT_DIR, "src", "fptaylor"))
sys.path.append(path.join(GIT_DIR, "src", "fpcore_parser", "src"))

import check_requirements

from datetime import date
from fpcore_logging import Logger
from exceptions import DomainError, UnsupportedError, NoPreError, BadPreError, FPTunerError
from fpcore_lexer import FPCoreLexer
from fpcore_parser import FPCoreParser
from z3_result import Z3Result
from tuned_expression import TunedExpression
from fptaylor_result import FPTaylorResult

import ast_modifications.all_modifications_ast as all_modifications_ast
import fptuner_argument_parser
import generate_graph
import generate_aggregated_graph
import os
import glob
import shutil

logger = Logger(level=Logger.LOW, color=Logger.green)

def sanitize_name(name):
    bad_chars = {".", ":", " ", "-", ",", "$"}
    for c in bad_chars:
        name = name.replace(c, "_")
    return name


def found_config(error_bound, fptaylor_error, tuned_res, args, ssa, names, signatures, rows, first_header):
    # Generate c file
    if args.cfile:
        name = sanitize_name(ssa.name)
        strnum = str(error_bound).replace(".","_").replace("-","m")
        func_name = "{}_error_{}".format(name, strnum)
        filename = func_name + ".c"
        tuned_res.name = func_name
        content = tuned_res.to_c_function()
        names.append(func_name)
        signatures.append(tuned_res.signature)
        with open(filename, "w") as f:
            f.write('#include "impls.h"\n\n')
            f.write(content)

    # Add to data rows
    header, row = tuned_res.tsv()

    if first_header is None:
        first_header = header
    elif first_header != header:
        logger.error("Header mismatch: \n{} \n{}",
                     first_header, header)
        sys.exit(1)

    row.append(str(fptaylor_error))
    rows.append(row)

    return header, fptaylor_error



# raw_query -> { tuned_results_str -> (fptaylor_error, domains_passed) }
TUNED_RES_CACHE = dict()

# raw_query -> { z3_error_bound -> (fptaylor_error, domains_passed, tuned_res) }
Z3_ERROR_CACHE = dict()

def try_error_bound(error_bound, raw_query, args, ssa, names, signatures, rows, first_header):
    # Check cache
    z3_error_bound = 2*error_bound
    if raw_query not in Z3_ERROR_CACHE:
        Z3_ERROR_CACHE[raw_query] = dict()

    answers = Z3_ERROR_CACHE[raw_query]
    for old_z3_error_bound in sorted(answers.keys(), reverse=True):
        fpt_err, dom_pass, tr = answers[old_z3_error_bound]
        if fpt_err is not None and fpt_err < error_bound and dom_pass == True:
            logger("Used z3_error_cache\n")
            return found_config(error_bound, fpt_err, tr, args, ssa, names, signatures, rows, first_header)
        if fpt_err is None or fpt_err > error_bound:
            z3_error_bound = min(old_z3_error_bound, z3_error_bound)

    if raw_query not in TUNED_RES_CACHE:
        TUNED_RES_CACHE[raw_query] = dict()
    z3_cache = TUNED_RES_CACHE[raw_query]

    z3_times = list()
    fptaylor_times = list()
    domain_times = list()
    while True:
        z3_error_bound = z3_error_bound/2

        logger("Trying: {}".format(z3_error_bound))
        # 1. Tune to ther error bound
        try:
            start = time.time()
            zr = Z3Result(ssa, z3_error_bound)
            end = time.time()
            z3_times.append(end - start)
            logger("Time to run z3: {}", end - start)
        except FPTunerError:
            ## If we can't get this error bound, all tighter ones will fail
            logger.error("Unable to satisfy error bound")
            return None, None
        tuned_res = TunedExpression(ssa, zr)
        tuned_res_str = " ".join(tuned_res.tsv()[1][1:-1])
        logger("Chose config: {}", tuned_res_str)

        if tuned_res_str in z3_cache:
            fpt_err, dom_pass = z3_cache[tuned_res_str]
            if fpt_err is None or fpt_err > error_bound or dom_pass == False:
                logger("Used tuned_res_cache\n")
                continue

        # If a domain check fails we may be able to replace the op and retry
        try_with_lower_bound = False
        while True:

            # 2. Check that second order error is preserved
            logger("Checking 2nd order error")
            query = tuned_res.to_fptaylor()
            start = time.time()
            res = FPTaylorResult(query, FPTaylorResult.CHECK_CONFIG)
            end = time.time()
            fptaylor_times.append(end - start)
            logger("Time to get 2nd order error: {}", end - start)
            logger("FPTaylor error bound: {}", res.abs_error)
            logger("FPTaylor second order error: {}", res.second_order)
            answers[z3_error_bound] = (res.abs_error, None, tuned_res)
            z3_cache[tuned_res_str] = (res.abs_error, None)
            if res.div_by_zero or res.log_of_non_positive or res.inf_val:
                logger("FPTaylor thinks exceptional circumstances are possible")
                logger("Retrying with lower bound\n")
                try_with_lower_bound = True
                break
            elif res.abs_error is None:
                logger("FPTaylor did not find an error value")
                logger("Retrying with lower bound\n")
                try_with_lower_bound = True
                break
            elif res.abs_error > error_bound:
                logger("Retrying with lower bound\n")
                try_with_lower_bound = True
                break

            # 3. Check that domains are still valid
            logger("Checking domains")
            start = time.time()
            valid = tuned_res.check_domains()
            end = time.time()
            domain_times.append(end - start)
            logger("Time to check domains: {}", end - start)
            if valid is None:
                logger("Replaced operation and retrying")
                while valid is None:
                    start = time.time()
                    valid = tuned_res.check_domains()
                    end = time.time()
                    domain_times.append(end - start)
                    logger("Time to check domains: {}", end - start)
                logger("Finished replacing, trying 2nd order error")
                continue
            elif not valid:
                logger("Domains are not sound")
                logger("Retrying with lower bound")
                try_with_lower_bound = True
                answers[z3_error_bound] = (res.abs_error, False, tuned_res)
                z3_cache[tuned_res_str] = (res.abs_error, False)
                break
            else:
                try_with_lower_bound = False
                answers[z3_error_bound] = (res.abs_error, True, tuned_res)
                z3_cache[tuned_res_str] = (res.abs_error, True)
                break

        if not try_with_lower_bound:
            break

    logger("Total z3 time: {}", sum(z3_times))
    logger("Total fptaylor time: {}", sum(fptaylor_times))
    logger("Total domain time: {}\n\n", sum(domain_times))

    return found_config(error_bound, res.abs_error, tuned_res, args, ssa, names, signatures, rows, first_header)



def main(argv):
    args = fptuner_argument_parser.parse_args(argv)

    # Grab all functions from the modifications table
    sins = [row[1] for row in all_modifications_ast.OperationTable
            if row[0] == "sin"]
    exps = [row[1] for row in all_modifications_ast.OperationTable
            if row[0] == "exp"]
    logs = [row[1] for row in all_modifications_ast.OperationTable
            if row[0] == "log"]
    tans = [row[1] for row in all_modifications_ast.OperationTable
            if row[0] == "tan"]
    operations = {"sin": sins,
                  "exp": exps,
                  "log": logs,
                  "tan": tans}

    # Setup the search space
    search_space = {"bit_widths": ["fp64"], #args.bit_widths,
                    "operations": operations}

    lexer = FPCoreLexer()
    parser = FPCoreParser()

    graph_datafiles = list()
    for query_file in args.query_files:
        try:
            with open(query_file, "r") as f:
                text = f.read()

        except FileNotFoundError:
            logger.error("Unable to find file '{}'", query_file)
            continue

        # todo: add try catch for lex and parse errors
        tokens = lexer.tokenize(text)
        fpcores = parser.parse(tokens)

        if len(fpcores) == 0:
            logger.error("No FPCore found in file '{}'", query_file)
            continue

        for fpcore in fpcores:
            try:
                signatures = list()
                names = list()
                ssa = fpcore.to_single_assignment(search_space)
                if args.nightly:
                    print("<h1>{}</h1>".format(ssa.name), flush=True)
                else:
                    print(ssa.name, flush=True)

                start = time.time()
                ssa.get_fptaylor_forms()
                end = time.time()
                logger("Time to get taylor forms: {}", end - start)

                start = time.time()
                ssa.get_fptaylor_maximums()
                end = time.time()
                logger("Time to maximize forms: {}\n", end - start)

                first_header = None
                rows = []
                fptaylor_errors = []
                for e in args.error:
                    header, achieved_error = try_error_bound(e, str(fpcore), args, ssa, names, signatures, rows, first_header)
                    if first_header is None:
                        first_header = header
                    if achieved_error is None:
                        break
                    fptaylor_errors.append(achieved_error)

                if args.nightly:
                    print("<table>")
                    print("<tr><th>" + "</th><th>".join(first_header) + "</th></tr>")
                    for row in rows:
                        print("<tr><td>" + "</td><td>".join(row) + "</td></tr>")
                    print("</table>")
                    print("<img src='{}_time.png'>".format(sanitize_name(ssa.name)))
                else:
                    print("\t".join(first_header))
                    for row in rows:
                        print("\t".join(row))

                if args.cfile:
                    time_name = "{}_time.c".format(sanitize_name(ssa.name))
                    time_contents = ['#include "timing.h"',
                                     '#include "xmalloc.h"',
                                     '#include <float.h>',
                                     '#include <math.h>',
                                     '#include <stdio.h>']
                    for name,domain in ssa.inputs.items():
                        time_contents.append("const fp64 {}_LOW = {};".format(name, domain[0]))
                        time_contents.append("const fp64 {}_HIGH = {};".format(name, domain[1]))
                    time_contents.extend(["double "+s+";" for s in signatures])
                    time_contents.append("#define FUNC_COUNT ({})".format(len(signatures)))
                    functype = {1:"unop_fp64", 2:"binop_fp64", 3:"triop_fp64", 4:"quadop_fp64", 5:"quintop_fp64", 6:"hexop_fp64"}[len(ssa.inputs)]
                    time_contents.append("{} FUNCTIONS[FUNC_COUNT] = {{{}}};".format(functype, ",".join(names)))
                    time_contents.append("char* NAMES[FUNC_COUNT] = {{{}}};".format(",".join(['"'+n+'"' for n in names])))
                    time_contents.append("char* ERRORS[FUNC_COUNT] = {{{}}};".format(",".join(['"'+str(e)+'"' for e in fptaylor_errors])))
                    time_contents.extend(["int main(int argc, char** argv){",
                                          "size_t log2_values = 18;",
                                          "size_t secs = 10;",
                                          "size_t runs = 3;",
                                          "if (argc > 1) { log2_values = strtoul(argv[1], NULL, 10); }",
                                          "if (argc > 2) { secs = strtoul(argv[2], NULL, 10); }",
                                          "if (argc > 3) { runs = strtoul(argv[3], NULL, 10); }",
                                          "timing_data_fp64* data = time_{}({},".format(functype,
                                                                                        ",".join(["{}_LOW,{}_HIGH".format(n,n) for n in ssa.inputs])),
                                          "FUNC_COUNT, FUNCTIONS, NAMES, ERRORS, log2_values, runs, secs);"
                                          "print_timing_data_fp64(data);",
                                          "free_timing_data_fp64(data);",
                                          "return 0;",
                                          "}"])
                    with open(time_name, "w") as f:
                        f.write("\n".join(time_contents))
                    cfiles = glob.glob("*.c")
                    destfiles = [path.join(GIT_DIR, "cost-measurement/kerns/{}".format(c)) for c in cfiles]
                    try:
                        os.mkdir(path.join(GIT_DIR,"cost-measurement/kerns"))
                    except FileExistsError:
                        pass
                    for src,dest in zip(cfiles, destfiles):
                        shutil.move(src, dest)
                    graph_datafiles.append(generate_graph.graph(time_name))

            except DomainError as e:
                if e.lower is None and e.upper is None:
                    logger.error("No domain defined for '{}'", e.name)
                elif e.lower is None:
                    logger.error("No lower bound defined for '{}'", e.name)
                else:
                    logger.error("No upper bound defined for '{}'", e.name)

            except UnsupportedError as e:
                msg = "Found unsupported FPCore language statement type '{}'"
                logger.error(msg, e.statement_type)

            except NoPreError:
                logger.error("No :pre property defined")

            except BadPreError as e:
                logger.error("Unable to process precondition: '{}'", e.pre)


if __name__ == "__main__":
    start = time.time()
    try:
        retval = main(sys.argv)
    except KeyboardInterrupt:
        retval = 1

    end = time.time()
    logger("Total time: {}", end - start)
    sys.exit(retval)
